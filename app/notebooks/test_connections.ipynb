{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3efae332-0226-40f8-8a29-5395e86ea20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZenML version: 0.71.0\n"
     ]
    }
   ],
   "source": [
    "from zenml import __version__\n",
    "print(f\"ZenML version: {__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee770b0-2bcc-417e-8931-85a6b6abe749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb\", 27017)\n",
    "db = client.test_db\n",
    "print(db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300a9ed6-f7e1-4535-83bf-4ba2af9f2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='rag_collection')]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant = QdrantClient(host=\"qdrant\", port=6333)\n",
    "# list existing collections to test connection\n",
    "collections = qdrant.get_collections()\n",
    "print(collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2573e64-b040-4b65-9bed-87cd3665fbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! Streaming response...\n",
      "Full Response: Hello there! It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Get the Ollama host from environment variables\n",
    "ollama_host = os.getenv(\"OLLAMA_HOST\", \"http://host.docker.internal:11434\")\n",
    "\n",
    "# Define a test payload with the model name\n",
    "payload = {\n",
    "    \"model\": \"llama2\",  # Replace with the name of an available model\n",
    "    \"prompt\": \"Hello, world!\",\n",
    "    \"parameters\": {\"max_tokens\": 50}\n",
    "}\n",
    "full_response = \"\"\n",
    "try:\n",
    "    # Send a POST request to the Ollama API\n",
    "    with requests.post(f\"{ollama_host}/api/generate\", json=payload, stream=False) as response:\n",
    "        if response.status_code == 200:\n",
    "            print(\"Connection successful! Streaming response...\")\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    data = json.loads(line.decode(\"utf-8\"))\n",
    "                    full_response += data.get(\"response\", \"\")\n",
    "            print(\"Full Response:\", full_response)\n",
    "        else:\n",
    "            print(f\"Connection failed with status code {response.status_code}\")\n",
    "            print(\"Response:\", response.text)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error connecting to Ollama:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
