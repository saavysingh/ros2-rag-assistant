{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a56fc3-ec58-454a-bc74-85061e8e9b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /usr/local/lib/python3.9/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.9/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (58.1.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.68.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2620bcd1-3619-402a-919d-bd323dc0549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "import gradio as gr\n",
    "from pymongo import MongoClient\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Connect to Qdrant (adjust host/port if different)\n",
    "qdrant_client = QdrantClient(host='rag_qdrant', port=6333)\n",
    "collection_name = 'rag_collection'\n",
    "\n",
    "# Embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7271792b-9962-4ec6-8c9d-adc5d587aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def retrieve_relevant_chunks(query_embedding, top_k=5):\n",
    "    search_results = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "    retrieved_texts = [result.payload['chunk'] for result in search_results]\n",
    "    return retrieved_texts\n",
    "\n",
    "def call_ollama(prompt, model=\"llama2\"):\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"options\": {\n",
    "            \"stream\": False  # Request a full response, not streaming\n",
    "        }\n",
    "    }\n",
    "\n",
    "    url = os.getenv(\"OLLAMA_HOST\", \"http://host.docker.internal:11434\")\n",
    "    try:\n",
    "        # Send the POST request\n",
    "        response = requests.post(f\"{url}/api/generate\", json=payload, timeout=30)  # Add timeout\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Handle raw response in case of multiple JSON objects\n",
    "        raw_response = response.text.strip()  # Raw response as text\n",
    "        # print(\"Raw Response:\", raw_response)\n",
    "\n",
    "        # Combine 'response' fields from multiple JSON objects\n",
    "        responses = []\n",
    "        for line in raw_response.splitlines():\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if 'response' in data:\n",
    "                    responses.append(data['response'])\n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(f\"Error parsing line as JSON: {e} - Line: {line}\")\n",
    "\n",
    "        # Join all parts of the response\n",
    "        full_response = ''.join(responses)\n",
    "        return full_response if full_response else \"No response generated.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error calling Ollama API: {e}\")\n",
    "        return \"Sorry, I'm having trouble connecting to the language model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd9fa74-f1ee-4e1d-bb18-f00c8f8a9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query):\n",
    "    if not query.strip():\n",
    "        return \"Please enter a query.\"\n",
    "    \n",
    "    # Embed the user query\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "\n",
    "    # Retrieve relevant chunks from Qdrant\n",
    "    retrieved_texts = retrieve_relevant_chunks(query_embedding, top_k=5)\n",
    "\n",
    "    # Construct the prompt\n",
    "    context = \"\\n\".join(retrieved_texts)\n",
    "    prompt = f\"You are a helpful ROS2 expert assistant. Use the following context to answer the question. If you cannot find the answer in the context, say so. If providing code, ensure it's well-commented. Context:\\n{context}\\n\\nQuestion:\\n{query}\\n\\nAnswer:\"\n",
    "\n",
    "    answer = call_ollama(prompt, model=\"llama2\").strip()\n",
    "    if not answer:\n",
    "        answer = \"I'm not sure how to answer that.\"\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72acfe74-6ec5-48c9-9dee-185548fbb1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1633bd85ad97441a8e1f0704bd28e571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://rag_qdrant:6333/collections/rag_collection/points/search \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Answer: To navigate to a specific pose in ROS2, you can use the `navigate_to_pose` action server. This action server is implemented by the `bt_navigator` module and can be invoked using the `Navigation2` client. Here's an example code on how to navigate to a specific pose:\n",
      "```bash\n",
      "ros2 launch nav2_bringup tb3_simulation_launch.py params_file:=/path/to/your_params_file.yaml\n",
      "```\n",
      "In RViz, click on the \"2D Pose Estimate\" button at the top and point the location on the map as described in the `getting_started` section. Then, click on the \"Nav2 goal\" button and select the pose you want to navigate to. After that, click on the \"Controller plane\" button and drag to select the orientation of the robot.\n",
      "\n",
      "To change the output topic for the `navigate_to_pose` action server, you can use the `Tool Properties` panel in RViz.\n",
      "\n",
      "Here's some more information on how to use the `navigate_to_pose` action server:\n",
      "\n",
      "* The `navigate_to_pose` action server takes a single input parameter, which is a `geometry_msgs::msg::PoseStamped` message representing the desired pose of the robot.\n",
      "* You can invoke the `navigate_to_pose` action server using the `Navigation2` client, like this:\n",
      "```bash\n",
      "ros2 navigate_to_pose /path/to/desired/pose\n",
      "```\n",
      "Note that the `/path/to/desired/pose` parameter is a string representing the pose of the robot in the form of a `geometry_msgs::msg::PoseStamped` message.\n",
      "\n",
      "Here's an example code that demonstrates how to navigate to a specific pose using the `navigate_to_pose` action server:\n",
      "```python\n",
      "import rospy\n",
      "from geometry_msgs.msg import PoseStamped\n",
      "\n",
      "# Create a ROS node\n",
      "rospy.init_node('navigate_to_pose_example')\n",
      "\n",
      "# Set the desired pose of the robot\n",
      "desired_pose = PoseStamped()\n",
      "desired_pose.header.stamp = rospy.Time()\n",
      "desired_pose.header.frame_id = \"base_link\"\n",
      "desired_pose.position.x = 1.0\n",
      "desired_pose.position.y = 2.0\n",
      "desired_pose.orientation = 3.0\n",
      "\n",
      "# Invoke the navigate_to_pose action server\n",
      "rospy.root.navigate_to_pose(desired_pose)\n",
      "```\n",
      "In this code, we create a ROS node and set a desired pose for the robot using the `PoseStamped` message. Then, we invoke the `navigate_to_pose` action server with the desired pose as input. The `navigate_to_pose` action server will then navigate the robot to the desired pose.\n",
      "\n",
      "Note that this is just a basic example, and you may need to modify the code depending on your specific use case. Additionally, the `navigate_to_pose` action server may not always be able to navigate the robot directly to the desired pose due to limitations such as safety constraints or system state.\n"
     ]
    }
   ],
   "source": [
    "test_query = \"How do I navigate to a specific pose in ROS2? Can you provide me with code for this task?\"\n",
    "print(\"\\n Answer:\", generate_response(test_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66cd4eb-05d2-493d-bb76-8304b8f96de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:7860/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://localhost:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=generate_response,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"ROS2 RAG Assistant\",\n",
    "    description=\"Ask questions about ROS2. The system retrieves relevant info and uses the Llama2 model via Ollama to generate an answer.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch(server_name=\"0.0.0.0\", server_port=7860, share=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
