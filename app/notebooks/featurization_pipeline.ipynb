{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305e6c87-fd7c-42dd-a6bf-fa3a8420eb68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /usr/local/lib/python3.9/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.9/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.68.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.1)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f490a314-8019-42f6-8d2a-ba7d6509e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZenML\n",
    "from zenml import pipeline, step\n",
    "\n",
    "# General\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# MongoDB\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct, VectorParams, Distance\n",
    "\n",
    "# Embedding Model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# For logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15facd79-012a-4121-b77b-01f2a357c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def load_data_from_mongodb() -> list:\n",
    "    logger.info(\"Loading data from MongoDB...\")\n",
    "    \n",
    "    client = MongoClient('mongodb://rag_mongodb:27017/')\n",
    "    db = client['rag_db']\n",
    "    collection = db['raw_data']\n",
    "    \n",
    "    documents = list(collection.find())\n",
    "    logger.info(f\"Loaded {len(documents)} documents from MongoDB.\")\n",
    "    \n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9d4d33-5b37-4744-b181-2d87e33345dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def categorize_and_preprocess_data(documents: list) -> list:\n",
    "    logger.info(\"Categorizing and preprocessing data...\")\n",
    "    \n",
    "    processed_data = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        content = doc['content']\n",
    "        file_path = doc['path']\n",
    "        source = doc['source']\n",
    "        \n",
    "        # Determine the category based on file extension\n",
    "        if file_path.endswith('.md') or file_path.endswith('.rst'):\n",
    "            category = 'article'\n",
    "            # Additional preprocessing for articles if needed\n",
    "        elif file_path.endswith('.py'):\n",
    "            category = 'code'\n",
    "            # Remove comments and docstrings if necessary\n",
    "            content = remove_comments_and_docstrings(content)\n",
    "        else:\n",
    "            category = 'other'\n",
    "        \n",
    "        processed_data.append({\n",
    "            'url': doc['url'],\n",
    "            'path': file_path,\n",
    "            'repository': doc['repository'],\n",
    "            'branch': doc['branch'],\n",
    "            'content': content,\n",
    "            'source': source,\n",
    "            'category': category\n",
    "        })\n",
    "    \n",
    "    logger.info(f\"Categorized and processed {len(processed_data)} documents.\")\n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e738c9-b2fb-47a7-83b3-45976f3aa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def remove_comments_and_docstrings(source):\n",
    "    \"\"\"\n",
    "    Remove comments and docstrings from Python source code.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed = ast.parse(source)\n",
    "        for node in ast.walk(parsed):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef, ast.Module)):\n",
    "                if node.body and isinstance(node.body[0], ast.Expr):\n",
    "                    if hasattr(node.body[0], 'value') and isinstance(node.body[0].value, ast.Str):\n",
    "                        node.body = node.body[1:]\n",
    "        return ast.unparse(parsed)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error parsing Python code: {e}\")\n",
    "        return source  # Return original source if parsing fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55dbd8e-7470-49f8-bab5-4457c71fedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def chunk_data(processed_data: list) -> list:\n",
    "    logger.info(\"Chunking data...\")\n",
    "    \n",
    "    chunked_data = []\n",
    "    max_chunk_size = 500  # Adjust based on your embedding model's max input length\n",
    "    \n",
    "    for doc in processed_data:\n",
    "        content = doc['content']\n",
    "        doc_id = f\"{doc['repository']}_{doc['path']}\".replace('/', '_')\n",
    "        \n",
    "        # Split content into chunks\n",
    "        content_length = len(content)\n",
    "        chunks = [content[i:i+max_chunk_size] for i in range(0, content_length, max_chunk_size)]\n",
    "        \n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            chunked_data.append({\n",
    "                'doc_id': str(doc_id),\n",
    "                'chunk_id': f\"{str(doc_id)}_{idx}\",\n",
    "                'chunk': chunk,\n",
    "                'metadata': {\n",
    "                    'url': doc['url'],\n",
    "                    'path': doc['path'],\n",
    "                    'repository': doc['repository'],\n",
    "                    'branch': doc['branch'],\n",
    "                    'source': doc['source'],\n",
    "                    'category': doc['category']\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    logger.info(f\"Created {len(chunked_data)} chunks from documents.\")\n",
    "    return chunked_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97457f3-7597-4c2e-aa48-aa42e8e3e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def generate_embeddings(chunked_data: list) -> list:\n",
    "    logger.info(\"Generating embeddings...\")\n",
    "    \n",
    "    if not chunked_data:\n",
    "        logger.warning(\"No data to generate embeddings for!\")\n",
    "        return []\n",
    "    \n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    batch_size = 32  # Adjust based on your hardware capabilities\n",
    "    \n",
    "    embeddings = []\n",
    "    total_batches = (len(chunked_data) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(0, len(chunked_data), batch_size):\n",
    "        batch = chunked_data[i:i+batch_size]\n",
    "        texts = [item['chunk'] for item in batch]\n",
    "        try:\n",
    "            batch_embeddings = model.encode(texts)\n",
    "            for idx, item in enumerate(batch):\n",
    "                item['embedding'] = batch_embeddings[idx].tolist()\n",
    "            embeddings.extend(batch)\n",
    "            logger.info(f\"Processed batch {(i//batch_size)+1}/{total_batches}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embeddings for batch {i//batch_size}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    logger.info(f\"Generated embeddings for {len(embeddings)} chunks.\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad94001c-e014-4d28-a916-b465404262b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def store_embeddings_in_qdrant(chunked_data: list):\n",
    "    logger.info(\"Storing embeddings in Qdrant...\")\n",
    "    \n",
    "    try:\n",
    "        client = QdrantClient(host='rag_qdrant', port=6333)\n",
    "        \n",
    "        # Define collection parameters\n",
    "        collection_name = 'rag_collection'\n",
    "        vector_size = len(chunked_data[0]['embedding'])\n",
    "        \n",
    "        # Check if collection exists and recreate\n",
    "        try:\n",
    "            client.get_collection(collection_name)\n",
    "            client.delete_collection(collection_name)\n",
    "            logger.info(f\"Deleted existing collection: {collection_name}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "        )\n",
    "        \n",
    "        # Prepare data for Qdrant\n",
    "        batch_size = 100  # Adjust based on your needs\n",
    "        for i in range(0, len(chunked_data), batch_size):\n",
    "            batch = chunked_data[i:i+batch_size]\n",
    "            points = []\n",
    "            for idx, item in enumerate(batch):\n",
    "                # Generate a positive integer ID using the position in the dataset\n",
    "                point_id = i * batch_size + idx + 1  # Ensures positive, unique IDs starting from 1\n",
    "                \n",
    "                point = PointStruct(\n",
    "                    id=point_id,  # Use the positive integer ID\n",
    "                    vector=item['embedding'],\n",
    "                    payload={\n",
    "                        **item['metadata'],\n",
    "                        'chunk_id': item['chunk_id'],\n",
    "                        'doc_id': item['doc_id'],\n",
    "                        'chunk': item['chunk']\n",
    "                    }\n",
    "                )\n",
    "                points.append(point)\n",
    "            \n",
    "            try:\n",
    "                # Upload batch to Qdrant\n",
    "                client.upsert(\n",
    "                    collection_name=collection_name,\n",
    "                    points=points\n",
    "                )\n",
    "                logger.info(f\"Uploaded batch of {len(points)} embeddings to Qdrant (IDs {points[0].id} to {points[-1].id})\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error uploading batch: {str(e)}\")\n",
    "                # Log the first failing point for debugging\n",
    "                if points:\n",
    "                    logger.error(f\"First point in failing batch - ID: {points[0].id}\")\n",
    "                raise\n",
    "        \n",
    "        logger.info(f\"Successfully stored all {len(chunked_data)} embeddings in Qdrant.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error storing embeddings in Qdrant: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74788f49-d81b-475a-8718-ab7a665c9d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mPipeline completed successfully!\u001b[0m\n",
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeaturization_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mYou can visualize your pipeline runs in the \u001b[0m\u001b[1;36mZenML Dashboard\u001b[1;35m. In order to try it locally, please run \u001b[0m\u001b[1;36mzenml login --local\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of step \u001b[0m\u001b[1;36mload_data_from_mongodb\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of step \u001b[0m\u001b[1;36mcategorize_and_preprocess_data\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of step \u001b[0m\u001b[1;36mchunk_data\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of step \u001b[0m\u001b[1;36mgenerate_embeddings\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mstore_embeddings_in_qdrant\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStoring embeddings in Qdrant...\u001b[0m\n",
      "\u001b[1;35mHTTP Request: GET \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mHTTP Request: DELETE \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mDeleted existing collection: rag_collection\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1 to 100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 10001 to 10100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 20001 to 20100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 30001 to 30100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 40001 to 40100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 50001 to 50100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 60001 to 60100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 70001 to 70100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 80001 to 80100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 90001 to 90100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 100001 to 100100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 110001 to 110100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 120001 to 120100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 130001 to 130100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 140001 to 140100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 150001 to 150100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 160001 to 160100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 170001 to 170100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 180001 to 180100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 190001 to 190100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 200001 to 200100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 210001 to 210100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 220001 to 220100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 230001 to 230100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 240001 to 240100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 250001 to 250100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 260001 to 260100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 270001 to 270100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 280001 to 280100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 290001 to 290100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 300001 to 300100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 310001 to 310100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 320001 to 320100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 330001 to 330100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 340001 to 340100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 350001 to 350100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 360001 to 360100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 370001 to 370100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 380001 to 380100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 390001 to 390100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 400001 to 400100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 410001 to 410100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 420001 to 420100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 430001 to 430100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 440001 to 440100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 450001 to 450100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 460001 to 460100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 470001 to 470100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 480001 to 480100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 490001 to 490100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 500001 to 500100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 510001 to 510100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 520001 to 520100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 530001 to 530100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 540001 to 540100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 550001 to 550100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 560001 to 560100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 570001 to 570100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 580001 to 580100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 590001 to 590100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 600001 to 600100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 610001 to 610100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 620001 to 620100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 630001 to 630100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 640001 to 640100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 650001 to 650100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 660001 to 660100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 670001 to 670100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 680001 to 680100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 690001 to 690100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 700001 to 700100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 710001 to 710100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 720001 to 720100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 730001 to 730100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 740001 to 740100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 750001 to 750100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 760001 to 760100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 770001 to 770100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 780001 to 780100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 790001 to 790100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 800001 to 800100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 810001 to 810100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 820001 to 820100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 830001 to 830100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 840001 to 840100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 850001 to 850100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 860001 to 860100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 870001 to 870100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 880001 to 880100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 890001 to 890100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 900001 to 900100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 910001 to 910100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 920001 to 920100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 930001 to 930100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 940001 to 940100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 950001 to 950100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 960001 to 960100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 970001 to 970100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 980001 to 980100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 990001 to 990100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1000001 to 1000100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1010001 to 1010100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1020001 to 1020100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1030001 to 1030100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1040001 to 1040100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1050001 to 1050100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1060001 to 1060100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1070001 to 1070100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1080001 to 1080100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1090001 to 1090100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1100001 to 1100100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1110001 to 1110100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1120001 to 1120100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1130001 to 1130100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1140001 to 1140100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1150001 to 1150100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1160001 to 1160100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1170001 to 1170100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1180001 to 1180100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1190001 to 1190100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1200001 to 1200100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1210001 to 1210100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1220001 to 1220100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1230001 to 1230100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1240001 to 1240100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1250001 to 1250100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1260001 to 1260100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1270001 to 1270100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1280001 to 1280100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1290001 to 1290100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1300001 to 1300100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1310001 to 1310100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1320001 to 1320100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1330001 to 1330100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1340001 to 1340100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1350001 to 1350100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1360001 to 1360100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1370001 to 1370100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1380001 to 1380100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1390001 to 1390100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1400001 to 1400100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1410001 to 1410100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1420001 to 1420100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1430001 to 1430100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 100 embeddings to Qdrant (IDs 1440001 to 1440100)\u001b[0m\n",
      "\u001b[1;35mHTTP Request: PUT \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points?wait=true\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[1;35mUploaded batch of 7 embeddings to Qdrant (IDs 1450001 to 1450007)\u001b[0m\n",
      "\u001b[1;35mSuccessfully stored all 14507 embeddings in Qdrant.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mstore_embeddings_in_qdrant\u001b[1;35m has finished in \u001b[0m\u001b[1;36m4.788s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m4.831s\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First, create a global variable to store the results\n",
    "pipeline_results = None\n",
    "\n",
    "@pipeline\n",
    "def featurization_pipeline():\n",
    "    try:\n",
    "        documents = load_data_from_mongodb()\n",
    "        if not documents:\n",
    "            logger.error(\"No documents loaded from MongoDB!\")\n",
    "            return None\n",
    "            \n",
    "        processed_data = categorize_and_preprocess_data(documents)\n",
    "        if not processed_data:\n",
    "            logger.error(\"No documents after preprocessing!\")\n",
    "            return None\n",
    "            \n",
    "        chunked_data = chunk_data(processed_data)\n",
    "        if not chunked_data:\n",
    "            logger.error(\"No chunks created!\")\n",
    "            return None\n",
    "            \n",
    "        chunked_data_with_embeddings = generate_embeddings(chunked_data)\n",
    "        if not chunked_data_with_embeddings:\n",
    "            logger.error(\"No embeddings generated!\")\n",
    "            return None\n",
    "            \n",
    "        store_embeddings_in_qdrant(chunked_data_with_embeddings)\n",
    "        logger.info(\"Pipeline completed successfully!\")\n",
    "        \n",
    "        # Return the results\n",
    "        return chunked_data_with_embeddings\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Run the pipeline and store results\n",
    "pipeline_instance = featurization_pipeline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "916509c9-331b-4915-9cf0-fae96f4bf894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mUse pytorch device_name: cpu\u001b[0m\n",
      "\u001b[1;35mLoad pretrained SentenceTransformer: all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2f986892324b3c9ae99dd8fbf64da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mHTTP Request: POST \u001b[0m\u001b[34mhttp://rag_qdrant:6333/collections/rag_collection/points/search\u001b[1;35m \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\n",
      "Search Results for: 'What is ROS?'\n",
      "--------------------------------------------------\n",
      "Score: 0.6981\n",
      "Repository: ros2/ros2_documentation\n",
      "Path: source/Releases/Alpha-Overview.rst\n",
      "Category: article\n",
      "Chunk: ----------------------------------------------------- .. contents:: Table of Contents :local: Background ^^^^^^^^^^ As explained in a `design article <https://design.ros2.org/articles/why_ros2.html>`_...\n",
      "--------------------------------------------------\n",
      "Score: 0.6934\n",
      "Repository: ros2/ros2_documentation\n",
      "Path: source/Releases/Alpha-Overview.rst\n",
      "Category: article\n",
      "Chunk: luding the core libraries and core command line tools. Pretty much anything not listed above is not included in this release. The next steps are described in the `Roadmap <../../The-ROS2-Project/Roadm...\n",
      "--------------------------------------------------\n",
      "Score: 0.6873\n",
      "Repository: ros2/examples\n",
      "Path: README.md\n",
      "Category: article\n",
      "Chunk: ROS 2 examples ============== To see some of these examples in use, visit the ....\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now test the results\n",
    "def search_qdrant(query_text: str, limit: int = 3):\n",
    "    try:\n",
    "        # Connect to Qdrant\n",
    "        qdrant_client = QdrantClient(host='rag_qdrant', port=6333)\n",
    "        \n",
    "        # Load the same model used in the pipeline\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Generate embedding for the query\n",
    "        query_vector = model.encode(query_text)\n",
    "        \n",
    "        # Ensure the query vector is a list of floats\n",
    "        if not isinstance(query_vector, list):\n",
    "            query_vector = query_vector.tolist()\n",
    "        \n",
    "        # Log the query vector for debugging\n",
    "        logger.debug(f\"Query vector: {query_vector[:10]}...\")  # Log first 10 elements\n",
    "        \n",
    "        # Search\n",
    "        search_results = qdrant_client.search(\n",
    "            collection_name='rag_collection',\n",
    "            query_vector=query_vector,\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nSearch Results for: '{query_text}'\")\n",
    "        print(\"-\" * 50)\n",
    "        for result in search_results:\n",
    "            print(f\"Score: {result.score:.4f}\")\n",
    "            print(f\"Repository: {result.payload.get('repository')}\")\n",
    "            print(f\"Path: {result.payload.get('path')}\")\n",
    "            print(f\"Category: {result.payload.get('category')}\")\n",
    "            print(f\"Chunk: {result.payload.get('chunk')[:200]}...\")  # Show first 200 chars\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error searching Qdrant: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "search_qdrant(\"What is ROS?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
